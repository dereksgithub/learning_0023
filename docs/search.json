[
  {
    "objectID": "week6.html#javascript-and-gee-basics",
    "href": "week6.html#javascript-and-gee-basics",
    "title": "Week 6 Introduction to Google Earth Engine",
    "section": "JavaScript and GEE Basics",
    "text": "JavaScript and GEE Basics\nGoogle Earth Engine is a cloud platform developed by Google for scientific data analysis. (Reis, Datia, and Pós-de-Mina Pato 2020) GEE can handle large datasets in a relatively faster than many other traditional commercial software, its mature integration with JavaScript also enables new users to master the tool suite with a shallower learning curve.(Cardille et al. 2022) JavaScript is the language used in GEE code editor, it is an essential tool for front-end development, enabling developers to implement complex and interactive websites. JavaScript also interacts with HTML and CSS to style and build the user interface. I have also summarised some useful introduction materials for learning GEE here in the term summary.\nHere is a basic block to code a function:\nfunction sayHi(name) {\n    alert(\"Hi,\" + name + \"!\");\n}\n\nsayHi(\" guys, \"); // Pops up \"Hi, guys, !\""
  },
  {
    "objectID": "week6.html#gee-case-study-bristol",
    "href": "week6.html#gee-case-study-bristol",
    "title": "Week 6 Introduction to Google Earth Engine",
    "section": "GEE Case Study Bristol",
    "text": "GEE Case Study Bristol\nFirst, I gathered air quality data over Bristol. But the resolution from Sentinel 5P was not ideal, thus I zoomed out in order to find places with high NO2 levels, in the end, even London is included. At this resolution, it is obvious that we will need more image processing and better resolution to have fine-grained data on urban air quality\n\n\n\nNO2 Level Over Bristol to London from Sentinel 5P\n\n\n\nAir Quality, SAVI, ARVI, NDVI and NDWI\nIn this introductory study of GEE, I have examined the NO2 from Sentinel 5P and calculated NDVI, NDWI, SAVI and ARVI for Bristol. Time from the data used are Sentinel 2 and Sentinel 5P (for NO2) from 2021-Jan-01 to 2023-Dec-30, I made a date slider for the user to drag to select which data from a 30-day window. Rarely, the selection won’t be valid, that is because the filter that I coded for the cloud is very low 5, and the Sentinel 2 images tend to be more cloudy for Bristol, please refresh the webpage and try another month. Most of the time it is working, due to the confined time-frame, I will be optimising this app and its UI in the future. For now, NO2 is not bounded, as the Sentinel 5P data is low-resolution compared to Sentinel 2, thus NDVI, NDWI, SAVI and ARVI are bounded within the Bristol image, where as NO2 layer is not.\n\n\nPutting Everything Together\nHere is the link to the lookup app for Bristol, it is also embedded as follows:\n\n\n\n\nFor the legend in this GEE app, I have modified and derived the code from: Open Geo Blog. The colour code gradients for the four metrics are gathered from this website. The boundary for the app is Greater Bristol (or the Global Administrative Unit (GAUL) Layer Level 2 that contains Bristol) which is larger than the shapefile used to clip for the city boundary in the week 6 practical or the following screenshots.\nFor week 6, the author downloaded the Bristol City Boundary shape file, uploaded to the assets and clipped out images with only Bristol. This is smaller compared to the GAUL level 2 boundary used in the GEE app.\n\n\n\n\n\n\n\nNDVI, NDWI, SAVI and ARVI bounded by the Bristol Boundary"
  },
  {
    "objectID": "week6.html#principle-component-analysis",
    "href": "week6.html#principle-component-analysis",
    "title": "Week 6 Introduction to Google Earth Engine",
    "section": "Principle Component Analysis",
    "text": "Principle Component Analysis\nGEE can run PCA for satellite data, but the browser froze for a few minutes before the results are ready.\n\n\n\n\nBristol Boundary\n\n\n\n\n\nBristol Clip\n\n\n\n\n\nGLCM\n\n\n\n\n\nP1 and P2\n\n\n\n\n\nPC1\n\n\n\n\n\nPC2\n\n\n\n\n\nPC5\n\n\n\n\n\nPC6\n\n\n\nPC1 explains 77.17% of the variance in the dataset. With my visual assessment of the GLCM and PCA results, it is obvious PC1 and PC2 captures high NDWI and highly building dense areas repectively, whereas GLCM captures high-reflectance areas, it performs well on flat rooftops, making it suitable for identifying buildings.(Christaki et al. 2022) Such results are essential as the input of more complex models, such as classification models with dimensionalities reduced to PC1, PC2 and PC3 (together they explain 95.88% of variances). However, PC4 to PC6, or the other PCs on condition that they are still meaningful and not rounded to 0, can provide crucial insights to anomalies and noises.\n\nPCA Variance Results\n\n\nPC\nPercentage Variance Explained\n\n\n\n\nPC1\n77.17\n\n\nPC2\n11.40\n\n\nPC3\n7.31\n\n\nPC4\n2.41\n\n\nPC5\n1.58\n\n\nPC6\n0.11\n\n\nPC7\n0.03\n\n\nPC8 - PC20\n0.00"
  },
  {
    "objectID": "week6.html#more-on-gee-and-literature-review",
    "href": "week6.html#more-on-gee-and-literature-review",
    "title": "Week 6 Introduction to Google Earth Engine",
    "section": "More on GEE and Literature Review",
    "text": "More on GEE and Literature Review\nGoogle Earth Engine (GEE) offers a wide range of Earth data for researchers to use with easy access, this has led to a surge in publication using GEE. As a ECE major, I first explored the how GEE can support a vast user group scattered around the planet, and then looked into the recent trend in the scientific community with GEE.\n\nGEE Capabilities and Trend in Scientific Research\nThe system architecture of GEE is well designed to offer services at a large scale. This design allows the GEE to host massive amount of data while being scalable. Of course, being the birth-company for the famous MapReduce, it is obvious that hadnling massive amount of data is what Google does best. GEE offers a seamless integration with machine learning, whether it is using the API from python or code editor, the ML-workflow is well-integrated.\nDue to its advantages, more members from the scientific researchcommunity have been adapting GEE into their research in recent years.(Pham-Duc et al. 2023) GEE can provide geo-spatial analysis at a large-scale for free and its ample image series datasets are attractive features that drive a growing usage from the researchers. Furthermore, GEE can meet the needs of urban researcher since the nature or urban science research requires multi-faceted data and spatiotemporal data at large scale. GEE’s abundant city bird-view images in with sufficient temporal richness, encourages urban researcher to utilise it in conjunction with other urban data, sparking novel research findings about our growing metropolitan environment.\n\n\n\n\n System architecture of GEE (left) (Gorelick et al. 2017) and Annual number of articles published by the top ten journals (Pham-Duc et al. 2023)\n\n\n\nGEE Applications with GLCM\nIn the context of remote sensing for cities, GEE is employed in a diverse range of new applications and publications.(Amani et al. 2020) During the practical, I dived into the GLCM (Grey-Level Co-occurrence Matrix) and its applications in identifying potentials buildings in remote sensing datasets, this enabled me to have a wider range of methodology design for both my future research and the group assessment. There are many unique publications regarding GLCM, in the aspects of the theoretical construct of GLCM methods, Lan et al. Lan and Liu (2018) proposed a method to optimse the multi-scale parameters for the GLCM texture window. On the application side, researchers developed methods that combine the GLCM with SNIC (Simple Non-Iterative Clustering) to process the data for classification input in LULC (Land Use and Land Cover) research. (Tassi and Vizzari 2020) Other researchers have extended the GLCM methods to process multi-layered data and combined the modified GLCM with SVM (Support Vector Machine) to analyse collapsed buildings.(Moya et al. 2019) These new developments highlight the innovative usage and adaptation of GLCM for remote sensing research, however, it also indicates that such numeric methods should be handled with caution as its limitations may hinder the analysis accuracy if proper fine-tuning are not performed."
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "Week 6 Introduction to Google Earth Engine",
    "section": "Reflection",
    "text": "Reflection\nEmploying Google Earth Engine (GEE) certainly rekindles memories of my extensive collaborative efforts on diverse projects in Melbourne. During those projects, I relied on Nearmap (which was really high-res!) to coordinate with the design team and worked closely alongside engineers and GIS specialists. Together, we organised design modifications and participated the digital transformation of the construction processes. Unlike those days when my role was more supervisory and collaborative, I now find myself directly engaged with GEE, utilizing its powerful remote sensing capabilities for urban analysis and environmental applications.\nAlthough GEE offers a powerful tool suite for urban research, there may be certain limitations. First, it fosters a level of vendor lock-in where extensive use of GEE can lead to dependence on Google’s infrastructure, terms and conditions, posing risks to the research workflow. Furthermore, GEE is challenging to work with offline. Researchers with poor internet connection or working on remote sites may struggle to gain access to GEE. Data sharing with GEE can be more complicated than other platforms. Sharing custom-made shapefiles might turn out to be a complex process due to GEE’s data management policies and permissions. Finally but not the least, GEE can be difficult for non-coders to learn, what is available to it JavaScript library can be occasionally counter-intuitive.\nDespite GEE’s limitations, its versatile and lightweight nature, combined with its openness and collection of data, still weighs out its limitations. Researching with GEE on urban topics is still promising as the platform itself is robust and powerful for large datasets, besides, the GEE community is open and vibrant, there are many resources and people for turn to for collaboration and assistance.\n\n\n\n\nAmani, Meisam, Arsalan Ghorbanian, Seyed Ali Ahmadi, Mohammad Kakooei, Armin Moghimi, S Mohammad Mirmazloumi, Sayyed Hamed Alizadeh Moghaddam, et al. 2020. “Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 13: 5326–50.\n\n\nCardille, Jeffrey A, Nicholas E Clinton, Morgan A Crowley, and David S Saah. 2022. “Cloud-Based Remote Sensing with Google Earth Engine: Process and Prospects from a Large Edited Open-Access Book.” In AGU Fall Meeting Abstracts, 2022:ED32D–0552.\n\n\nChristaki, Marianna, Christos Vasilakos, Ermioni-Eirini Papadopoulou, Georgios Tataris, Ilias Siarkos, and Nikolaos Soulakellis. 2022. “Building Change Detection Based on a Gray-Level Co-Occurrence Matrix and Artificial Neural Networks.” Drones 6 (12): 414.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-Scale Geospatial Analysis for Everyone.” Remote Sensing of Environment 202: 18–27.\n\n\nLan, Zeying, and Yang Liu. 2018. “Study on Multi-Scale Window Determination for GLCM Texture Description in High-Resolution Remote Sensing Image Geo-Analysis Supported by GIS and Domain Knowledge.” ISPRS International Journal of Geo-Information 7 (5): 175.\n\n\nMoya, Luis, Homa Zakeri, Fumio Yamazaki, Wen Liu, Erick Mas, and Shunichi Koshimura. 2019. “3D Gray Level Co-Occurrence Matrix and Its Application to Identifying Collapsed Buildings.” ISPRS Journal of Photogrammetry and Remote Sensing 149: 14–28.\n\n\nPham-Duc, Binh, Ho Nguyen, Hien Phan, and Quan Tran-Anh. 2023. “Trends and Applications of Google Earth Engine in Remote Sensing and Earth Science Research: A Bibliometric Analysis Using Scopus Database.” Earth Science Informatics 16 (3): 2355–71.\n\n\nReis, Rui S, Nuno Datia, and Matilde Pós-de-Mina Pato. 2020. “A Primer on Understanding Google Earth Engine APIs.” I-ETC: ISEL Academic Journal of Electronics, Telecommunications and Computers 6 (1): 1–11.\n\n\nTassi, Andrea, and Marco Vizzari. 2020. “Object-Oriented Lulc Classification in Google Earth Engine Combining Snic, Glcm, and Machine Learning Algorithms.” Remote Sensing 12 (22): 3776."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Personal Introduction",
    "section": "",
    "text": "Hi, welcome to my CASA0023 Learning Diary. I’ll be using this website built with Quarto as my major recording system for weekly practicals and writings. This could not be possible without our amazing lecturer Dr. Maclachlan, our awesome PGTAs (Postgraduate Teaching Assisstants) and additional GEE support (and cool GEE app demos) from Dr. Ballinger.\nMy name is Mengyu Ding, I am an engineer by training. Graduated from University of Alberta, Edmonton, Canada, in 2015 with a B.Sc in Electrical Engineering. Afterwards, I have been lucky to work in the ITS (Intelligent Transportation Systems) industry and engineering consulting industry for many years. I’ve also got a Master of Information Technology from Monash University, Melbourne, Australia, in 2019. After my first master’s degree, I have been working as a graduate engineer for John Holland Group in Melbourne for a few years and then moved back to China to join a few interesting start-ups and scale-ups as product/solutions manager in the autonomous driving (V2X side) and smart cities industry. Career-wise, I am interested in transportation and smart cities mostly. I attend UCL to gear my career towards urban mobility and smart cities. The support and learning at UCL has been quite great. (and of course, the studying is sometimes sleep-depriving too!)\nBesides working, I like hiking, cooking and reading science literature or science fictions. I also enjoy building small gadgets, for example, I was into hand-made Corsi-Rosenthal boxes during 2021 and 2022.\n\n\n\n\nGIS Crew and I (in the middle) Surveying Hu-Hang-Yong Highway in Zhejiang Province for Installing RSUs (Road Side Units)\n\n\n\n\n\nMy Hand-made Portable Air-Filtering System (HEPA-13 + 2 x turbo fans + Active charcoal Filter) Powered bn a Powerbank"
  },
  {
    "objectID": "week1.html#overview",
    "href": "week1.html#overview",
    "title": "Week 1 Introduction to Remote Sensing",
    "section": "Overview",
    "text": "Overview\nFor the first week, we are introduced to the concept of remote sensing and how to download data and images collected by satellites and perform basic analysis with SNAP and R. Remote sensing is part of GIS but it involves more than just GIS."
  },
  {
    "objectID": "week1.html#remote-sensing-overview",
    "href": "week1.html#remote-sensing-overview",
    "title": "Week 1 Introduction to Remote Sensing",
    "section": "Remote Sensing Overview",
    "text": "Remote Sensing Overview\n\nActive vs Passive sensors\n\nActive: Emits EM waves or other energy from its own sensors (radar, LiDar etc.) to measure and capture the landscapes/features of the area of interest.\nPassive: Detects and captures the natural energy signals radiated by of the area of interest.\n\nA key concept in remote sensingis the electromagnetic waves and their interaction with the atmosphere and the Earth’s surface. I have also revisited the concept of diffusion, reflection, refraction and diffraction. Understanding such interactions is pivotal for interpreting satellite imagery and other remote sensing data. Thus, correction of atmospheric interference accurately is one of the most important directions of work for remote sensing.\nData in Remote Sensing:\nThere are many types of data in remote sensing, we can broadly categorise them into the following:\n\nSpectral Data: Measure of light reflectance or emission across the electromagnetic spectrum (different wavelength).\nSpatial Data: Location information, size, shape or other features of the Earth’s surface.\nTemporal Data: “Simply data that represents a state in time.” i.e. the remote sensing data with time stamps.\nRadiometric Data: The intensity of radiation captured by sensors, indicating the percentage of the sensed wavelength is being emitted or reflected.\nResolution Data: Describing the raw data’s spatial, spectral, temporal, and radiometric resolution.\nMultispectral Data: It means the data that contains two or more sets of EM frequencies.\nHyperspectral Data: Data from all available bands on spectrum.\nThermal Data: Data collected from thermal remote sensing, usually collected from a sensor’s thermal band.\nLiDar Data: Utilise laser to collect point-cloud data thus capturing three-dimensional information about the Earth’s surface.\nRadar Data: Data collected from sampling back-scattered electromagnetic waves.\nOptical Data: Data from the visible, near infrared and short-wave-infrared bands on the EM spectrum.\nGravity and Magnetic Field Data: offering insights into the gravitational and magnetic conditions of the Earth.\nMetadata: information that describes a dataset, usually covering dataset’s content, time of collection, quality, publisher, and other characteristics.\n\nFour resolutions: Remotely sensed data and applications will vary based on the four resolutions\n\nSpatial: Refers to the size of one pixel on the ground (e.g. 20cm or 30m) Higher Spatial resolution means finer details.\nSpectral: Describes the number and width of spectral bands the sensor records data in.\nTemporal: The frequency with which a sensor revisits the same location. A chart of temporal resolution for Visible/NIR Satellites. (Sutlieff, Berthoud, and Stinchcombe 2021)\nRadiometric: identify differences in light or reflectance, in practice this is the range of possible values, for example, an 8-bit sensor has values between 0 and 255 (256 possibilities), captures much fewer energy levels than an 11-bit sensor has values between 0 and 2047 (2048 possibilities), in this sense, the 11-bit sensors captures finer-grained data."
  },
  {
    "objectID": "week1.html#case-study-of-bristol",
    "href": "week1.html#case-study-of-bristol",
    "title": "Week 1 Introduction to Remote Sensing",
    "section": "Case Study of Bristol",
    "text": "Case Study of Bristol\nFor this practical, I picked Bristol as its distinct urban and suburb area split. The data is downloaded from EU Copernicus Data Portal and Earth Explorer. The Sentinel 2A data is from April 17th, 2022 and the Landsat 8 data is from Sept 07th, 2023.\nFirst, I performed a scatter analysis for the greater Bristol area that I have picked for the analysis, this includes a large portion of suburb land, which indicates high biomass in the analysis.\n\n\n\nScatter Plot Analysis\n\n\n\n\n\nHistogram Analysis\n\n\n\n\n\nSentinel 2 Image\n\n\n\n\n\nSentinel and Landsat Side-by-side\n\n\nLater on, I performed the down sampling for Sentinel-2A images to align its resolution with Landsat images.\n\n\n\nDown-sampling of Sentinel-2A Images"
  },
  {
    "objectID": "week1.html#results",
    "href": "week1.html#results",
    "title": "Week 1 Introduction to Remote Sensing",
    "section": "Results",
    "text": "Results\nAfter down-sampling Sentinel images and cross-analyzing it with LandSat of the POI, downtown area of Bristol, the result is recorded below, indicating high urban.\n\n\n\nWeek 1 Result"
  },
  {
    "objectID": "week1.html#literature-review-and-applications",
    "href": "week1.html#literature-review-and-applications",
    "title": "Week 1 Introduction to Remote Sensing",
    "section": "Literature Review and Applications",
    "text": "Literature Review and Applications\nRemote sensing is certainly more than what I have previously pictured, which involves mainly a great deal of image processing. On the contrary, it consists of a balanced amount of geophysics, actual physics, and last but not least geography. (Navalgund, Jayaraman, and Roy 2007) In short, it is an interdisciplinary realm comprised of decades of studies and applications. While traditional image processing or computer vision certainly plays an important role, (Wilkinson 1999) further development in remote sensing certainly will demand a deep understanding of GIS, atmospheric science, spectral analysis, environmental science, ecology, and sensor technology etc. (Batty 2013) Recent development in the research of transportation highlights the integration of remote sensing data into hybrid models for specific urban topics such as travel behaviour prediction.(Wang et al. 2024) The utility of remote sensing has traditionally been rooted in agricultural applications, however, its relevance to urban studies is increasingly being recognized, such as its application in urban sustainability. (Sabri et al. 2022)"
  },
  {
    "objectID": "week1.html#reflections",
    "href": "week1.html#reflections",
    "title": "Week 1 Introduction to Remote Sensing",
    "section": "Reflections",
    "text": "Reflections\nAside from the metaphysical overview of remote sensing as an interesting area of research, I further browsed around EU Copernicus Data Portal and Earth Explorer to see what data I can have access to, for future research uses within and beyond the module. This week’s introduction to remote sensing is intriguing, as when I was young I was always curious about our planet and I used to spend quite some time reading Nature History / Chinese National Geography. (and later on National Geographic in English) I have known that remote sensing enables the modern map makers to create highly-accurate images but never had the opportunity to dive deep into this realm.\nRemote sensing plays a pivotal role in environment monitoring and management which could potentially benefit many aspects of urban development and research offering key insights for urban resilience and combating climate change. Back when I was working with other ITS engineers in China, I have witnessed how remote sensing and UAV sensing is used for calibrating HD Maps. During that time, my tasks was primarily centred on the Vehicle-to-Everything (V2X) implementations and solution design. However, engaging in discussions about the application of Light Detection and Ranging (LiDar) technology in Unmanned Aerial Vehicle surveys, and the subsequent processing of the acquired raw data, presented an intriguing aspect of the project. My initial industrial knowledge of how satellite works and their communication bands etc. come from the person standing on my left, Mr. Ji, who was an experienced GIS engineer fluent in UAV survey data processing. He was a happy engineer and always willing to share his technical take, many of my UCL classmates has the same energy as Mr. Ji back in the days.\n\n\n\n\nBatty, Michael. 2013. “Big Data, Smart Cities and City Planning.” Dialogues in Human Geography 3 (3): 274–79.\n\n\nNavalgund, Ranganath R, V Jayaraman, and PS Roy. 2007. “Remote Sensing Applications: An Overview.” Current Science, 1747–66.\n\n\nSabri, S, A Rajabifard, Y Chen, N Chen, and H Sheng. 2022. “Editorial: Geospatial Understanding of Sustainable Urban Analytics Using Remote Sensing. Remote Sens. 2022, 14, 2748.” s Note: MDPI stays neutral with regard to jurisdictional claims in published ….\n\n\nSutlieff, Gary, Lucy Berthoud, and Mark Stinchcombe. 2021. “Using Satellite Data for CBRN (Chemical, Biological, Radiological, and Nuclear) Threat Detection, Monitoring, and Modelling.” Surveys in Geophysics 42: 727–55.\n\n\nWang, Qingyi, Shenhao Wang, Yunhan Zheng, Hongzhou Lin, Xiaohu Zhang, Jinhua Zhao, and Joan Walker. 2024. “Deep Hybrid Model with Satellite Imagery: How to Combine Demand Modeling and Computer Vision for Travel Behavior Analysis?” Transportation Research Part B: Methodological 179: 102869.\n\n\nWilkinson, Graeme G. 1999. “Recent Developments in Remote Sensing Technology and the Importance of Computer Vision Analysis Techniques.” Machine Vision and Advanced Image Processing in Remote Sensing: Proceedings of Concerted Action MAVIRIC (Machine Vision in Remotely Sensed Image Comprehension), 5–11."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "Week 2 Quarto and Xaringan",
    "section": "",
    "text": "Here is the slide made with Xaringan for CloudSat and its Cloud Profiling Radar (CPR).\n\n\n\n\n\n\n\n\nHere is the full screen slide!"
  },
  {
    "objectID": "week3.html#case-study-of-bristol---continued",
    "href": "week3.html#case-study-of-bristol---continued",
    "title": "Week 3 Atmosphere Corrections",
    "section": "Case Study of Bristol - Continued",
    "text": "Case Study of Bristol - Continued\nThis week’s topic is on correction, the author carried on with the Bristol study as the Bristol area happens to have overlap of Landsat 8 and 9. (Landsat 8 C1L1 for the first part of the practical time of capture is Jan19 to Jan29, 2024)\n\n\n\nSelecting the Landsat 8 and 9 Data with Overlap at Bristol for the second part of practical\n\n\nLandsat 8 image corrected (Dark Object Subtraction method) with adjusted reflectance values that account for atmospheric effects, leading to a more accurate image.\n\n\n\nDN Results\n\n\nThe values of the estimated minimum digital number (DN) across the image for Band 2, 3, and 4 that are considered to be affected by haze are 19, 12, and 8. Among the three, band 2 shows the most atmospheric scattering effects while band 4 shows the least around the red part of the spectrum.\n\n\n\nCorrected Bristol Area for Landsat 8 (Or a large area that includes Bristol)\n\n\n\nMerging Images\nIn the second part of the practical, I downloaded Landsat 8 and 9, L2, with cloud cover 0 to 5% taken at Nov/25/2023 and Sep/05/2023 respectively.\n\n\n\nNDVI at different levels\n\n\nAfter the NDVI plots, I clipped the shapefile of the Bristol surrounding area. (Again, it is acually a large area that includes Bristol and multiple other cities/towns)\n\n\n\nQGis Clipping\n\n\n\n\n\nPCA Result Summary\n\n\nAfter performing dimensioality reduction with PCA, the first 3 components contain 86.6% of variances. To analyse the source data collected here, the dimension can be reduced to PC1 to PC4 only, as they, in total, explains 95.098% of variance. Compared to the smaller study area tailored towards the urban areas of Bristol in week 6, this result is certainly less . This is because the area is largely grass and forest, not building-dense, Bristol city areas.\n\n\n\nPCA Result Plots\n\n\n\n\nGLCM\nUsing GLCM (Grey-Level C0-occurrence Matrix) to perform texture analysis for Landsat images. Homogeneity measures the closeness of the distribution of elements in the GLCM to the GLCM diagonal, indicating areas where pixel values are similar to their neighbors, while reflecting uniform textures within the image. Second moment, or energy, quantifies texture uniformity an indicator where higher values denote areas with more consistent or smooth textures.\nCorrelation assesses how a pixel’s value is predictably related to its neighbors, with high values indicating a linear or predictable relationship in gray-level values across the texture. For GLCM, Mean refers to the average intensity or gray level within the analyzed window, offering insights into the overall brightness or reflectance of the area being studied. GLCM’s applications are covered here.\n\n\n\nGLCM 4 Methods"
  },
  {
    "objectID": "week3.html#summary-of-correction-indices",
    "href": "week3.html#summary-of-correction-indices",
    "title": "Week 3 Atmosphere Corrections",
    "section": "Summary of Correction Indices",
    "text": "Summary of Correction Indices\nThe area of correction methods or ratio enhancement in remote sensing is rich and growing, I have summarised some key methods below:\nNormalized Difference Vegetation Index (NDVI) is a remote sensing index that measures the health and density of vegetation on the Earth’s surface. NIR represents the near-infrared light reflected by vegetation, and RED represents the visible red light reflected by vegetation.\n\n\\(NDVI = \\frac{(NIR - RED)}{(NIR+RED)}\\)\n\nAside from the NDVI, here are some other indicators that I have investigated and summarized:\n\nARVI (Atmospherically Resistant Vegetation Index) is commonly employed to tackle regions of high atmospheric aerosol content. It was originally proposed for remote sensing of EOS MODIS sensor. (Kaufman and Tanre 1992) The range for an ARVI is -1 to 1 where green vegetation generally falls between values of 0.20 to 0.80.\n\n\\(ARVI = \\frac{(NIR - RED - y * (RED - BLUE))}{(NIR + RED - y*(RED-BLUE))}\\)\nAccording to ArcGIS: “ARVI is a vegetation-based index that minimizes the effects of atmospheric scattering caused by rain, fog, dust, smoke, or air pollution.”\ny is a constant to correct for the atmospheric effects caused by aerosol scattering in red channel.\n\nNDMI (Normalized Difference Moisture Index) helps monitoring and mapping water content in soil and vegetation. (Wilson and Sader 2002) It is calculated as Near-Infrared’s and Short-Wave Infrared’s difference over sum.:\n\\(NDMI = \\frac{NIR - SWIR}{NIR + SWIR}\\)\n\nIn Landsat 8-9: \\(NDMI =\\frac{(Band5 - Band6)}{(Band5+Band6)}​\\)\n\nSAVI (Soil-Adjusted Vegetation Index) is originally constructed to minimize soil brightness influences on NDVI, especially useful in areas with sparse vegetation. (AR Huete 1988)\n\n\\(SAVI =\\frac{(NIR+Red+L)}{(NIR−Red)}​∗(1+L)\\)\nSAVI introduces a soil brightness correction factor (L) to adjust the NDVI calculation, making it more accurate in sparse vegetation areas.\nIn Landsat 8-9: \\(SAVI - \\frac{Band5 - Band4}{Band5 + Band4 +0.5}\\)\n\nMSAVI (Modified Soil-Adjusted Vegetation Index) is an adjustment of SAVI, designed to minimize bare soil background effects more effectively and optimize vegetation monitoring. (Qi et al. 1994)\n\n\\(MSAVI = \\frac{2*NIR + 1 - \\sqrt{(2*NIR+1)-8*(NIR-RED)}}{2}\\)\nIn Landsat 8-9: \\(SAVI - \\frac{2*Band5 + 1 - \\sqrt{(Band5+1)^2 -8*(Band5-Band4)}}{2}\\)\n\nGNDVI (Green Normalized Difference Vegetation Index) focuses on chlorophyll content, primarily on the green spectral region for enhanced sensitivity to vegetation density. (Gitelson, Kaufman, and Merzlyak 1996)\n\n\\[NDVI = \\frac{NIR - Green}{NIR +Green}\\]\nLandsat 8-9: \\(NDMI =\\frac{Band5 - Band3}{Band5 + Band3}\\)\n\nEVI (Enhanced Vegetation Index) was proposed to improve the sensitivity in high biomass regions and improves vegetation monitoring through a de-coupling of the canopy background signal and a reduction in atmospheric influences. (Alfredo Huete et al. 2002)\n\n\\(EVI=G \\frac{(NIR−Red)}{(NIR+C1⋅Red−C2⋅Blue+L)}\\)\nIn Landsat 8-9: \\(EVI = 2.5 * \\frac{Band5 - Band4}{Band5 + 6* Band4 - 7.5*Band2 + 1}\\)\n\nNDWI (Normalized Difference Water Index) was formulated for the detection of liquid water and moisture content of vegetation and soil.(Gao 1996)\n\n\\(NDWI_{veg​}= \\frac{(NIR+Green)}{(NIR−Green)}\\)\nIn Landsat 8-9: \\(NDWI = \\frac{Band4-Band2}{Band4+band2}\\)\n\n\nThese indicators, are sufficient only for basic analysis demands, to derive more hidden relations, more modern techniques such as deep learning,(Ma et al. 2019) and Semi-supervised representation learning (Yan et al. 2020) can also be employed."
  },
  {
    "objectID": "week3.html#literature-review-and-applications",
    "href": "week3.html#literature-review-and-applications",
    "title": "Week 3 Atmosphere Corrections",
    "section": "Literature Review and Applications",
    "text": "Literature Review and Applications\nIntegrating the most appropriate remote sensing metrics for urban analytics is pivotal effective city planning or addressing other built-environment challenges. Among these measures, NDVI as is widely used for monitoring urban vegetation and urban green space,(Xue, Su, et al. 2017) whereas NDWI plays a critical role in urban water body and drought monitoring, it is also important for urban fire prevention.(Zhu 2017) Other metrics, such as ARVI, EVI, SAVI, MSAVI, and NDMI are still relevant in the industry and contemporary urban science, but recent studies call for both enhancement of the indices and nuanced applications. As suggested in many publications, such correction methods can be further refined to optimized the data contamination brought by atmospheric or other factors. Zhou et al. (2021) proposed the use of HANTS model (Harmonic Analysis of Time Series) to further optimize the parameter settings for NDVI reconstruction at a global scale and over longer period of time. Such methods are unique and well-rooted under today’s hype of LLM or “trying DL/complex machine learning frameworks on all problems”. Thus, investigations on further optimising the traditional correction methods with explainable models future research remains relevant and important."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "Week 3 Atmosphere Corrections",
    "section": "Reflection",
    "text": "Reflection\nReflecting on this week’s learning, it’s evident that the field of remote sensing is both complex and immensely powerful. Although, I am still seeing just seeing the tip of the iceberg by far, I do believe in the future of interdisciplinary potentials of remote sensing with city research. The process of selecting appropriate RS imagery, applying correction techniques, and utilizing various indices for environmental analysis is intricate but essential for extracting meaningful and reliable insights from the satellite data.(Jensen 1996) This knowledge not only enriched my technical skills but also enhanced myappreciation for the meticulous work behind the scenes of environmental monitoring and analysis.\nIn my continued case study of Bristol, served as a concept preview of the corrections in remote sensing and its applicability in real-world scenarios such as vegetation monitoring. The processed illustrated the importance of careful data selection, processing, and analytically flow in achieving robust outcomes. Furthermore, the discussion on correction methods and the summary of detailes of various vegetation and soil indices provided a comprehensive understanding of the tools and techniques.\nAs we continue our journey through the remote sensing module, this week’s focus on image correction and enhancements has laid a solid foundation for understanding the nuanced internal mechanics of satellite data processing. It has also sparked my curiosity about how these techniques can be applied to other areas of study, especially for urban resilience planning, smart cities design and disaster management. The insights gained this week will prepare us well regarding the basics for our future remote sensing projects.\n\n\n\n\nGao, Bo-Cai. 1996. “NDWI—a Normalized Difference Water Index for Remote Sensing of Vegetation Liquid Water from Space.” Remote Sensing of Environment 58 (3): 257–66.\n\n\nGitelson, Anatoly A, Yoram J Kaufman, and Mark N Merzlyak. 1996. “Use of a Green Channel in Remote Sensing of Global Vegetation from EOS-MODIS.” Remote Sensing of Environment 58 (3): 289–98.\n\n\nHuete, Alfredo, Kamel Didan, Tomoaki Miura, E Patricia Rodriguez, Xiang Gao, and Laerte G Ferreira. 2002. “Overview of the Radiometric and Biophysical Performance of the MODIS Vegetation Indices.” Remote Sensing of Environment 83 (1-2): 195–213.\n\n\nHuete, AR. 1988. “A Soil-Adjusted Vegetation Index (SAVI). Remote Ssensing of Environment, 25, 295-309.”\n\n\nJensen, John R. 1996. “Introductory Digital Image Processing: A Remote Sensing Perspective.”\n\n\nKaufman, Yoram J, and Didier Tanre. 1992. “Atmospherically Resistant Vegetation Index (ARVI) for EOS-MODIS.” IEEE Transactions on Geoscience and Remote Sensing 30 (2): 261–70.\n\n\nMa, Lei, Yu Liu, Xueliang Zhang, Yuanxin Ye, Gaofei Yin, and Brian Alan Johnson. 2019. “Deep Learning in Remote Sensing Applications: A Meta-Analysis and Review.” ISPRS Journal of Photogrammetry and Remote Sensing 152: 166–77.\n\n\nQi, Jiaguo, Abdelghani Chehbouni, Alfredo R Huete, Yann H Kerr, and Soroosh Sorooshian. 1994. “A Modified Soil Adjusted Vegetation Index.” Remote Sensing of Environment 48 (2): 119–26.\n\n\nWilson, Emily Hoffhine, and Steven A Sader. 2002. “Detection of Forest Harvest Type Using Multiple Dates of Landsat TM Imagery.” Remote Sensing of Environment 80 (3): 385–96.\n\n\nXue, Jinru, Baofeng Su, et al. 2017. “Significant Remote Sensing Vegetation Indices: A Review of Developments and Applications.” Journal of Sensors 2017.\n\n\nYan, Peiyao, Feng He, Yajie Yang, and Fei Hu. 2020. “Semi-Supervised Representation Learning for Remote Sensing Image Classification Based on Generative Adversarial Networks.” IEEE Access 8: 54135–44.\n\n\nZhou, Jie, Li Jia, Massimo Menenti, and Xuan Liu. 2021. “Optimal Estimate of Global Biome—Specific Parameter Settings to Reconstruct NDVI Time Series with the Harmonic ANalysis of Time Series (HANTS) Method.” Remote Sensing 13 (21): 4251.\n\n\nZhu, Zhe. 2017. “Change Detection Using Landsat Time Series: A Review of Frequencies, Preprocessing, Algorithms, and Applications.” ISPRS Journal of Photogrammetry and Remote Sensing 130: 370–84."
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "Week 4 Remote Sensing and Policy Implications",
    "section": "Summary",
    "text": "Summary"
  },
  {
    "objectID": "week4.html#wildfire-monitoring-for-air-quality-with-remote-sensing",
    "href": "week4.html#wildfire-monitoring-for-air-quality-with-remote-sensing",
    "title": "Week 4 Remote Sensing and Policy Implications",
    "section": "Wildfire Monitoring for Air Quality with Remote Sensing",
    "text": "Wildfire Monitoring for Air Quality with Remote Sensing\nRemote sensing and policy implications are intricately linked, playing a pivotal role in addressing some of our most pressing challenges. The United Nations Sustainable Development Goals (UN SDGs) outline numerous objectives for urban and built environments. Recently, mountain and bush fires have significantly deteriorated the air quality in major parts of the world, to make the matters worse, the smogs can travel far from time to time, threatening the health and quality of life for a great many residents.\nConsequently, my case study, centred around Melbourne and its adjacent suburbs, aims to explore the integration of remote sensing for wildfire monitoring with urban air quality forecasting. This short study intends identify the potentials of integrating remote sensing into the current pipelines, thus provide policymakers and city councils with sufficient lead time to implement measures before smog affects residential areas. Potential policy integration could include distribution of air filtration systems, masks or the evacuation of affected populations. This pilot study seeks to investigate the policy ramifications of establishing such operational frameworks.\n\nA Case Study and Policy Implications for the Greater Melbourne Area\nThe goal for this short study is to explore the forecasting of smoke plume bush-fire to areas that may impact the residents and discuss policy implications. Focusing on Melbourne, with framework that includes remote sensing, intended to be integrated with sustainable future planning inspired the use of remote sensing for monitoring urban growth in Perth, WA. (MacLachlan et al. 2017)\nAs for the imagery, Sentinel 5P from Copernicus Program is offering sufficient resolutions. In terms of spatial resolution it covers up to a 5.5km x 3.5km area, Sentinel 5P also offers a daily global coverage, (revisits less than one day) providing enough temporal resolution. As for spectral resolution, Sentinel 5P offers accurate quantification of various atmospheric gases and pollutants including carbon monoxide(CO), nitrogen dioxide (NO2), ozone(O3), formaldehyde(HCHO), sulfur dioxide(SO2), methane(CH4) and aerosols thanks to its extensive spectral coverage which includes UV, VIS and NIR bands.(Victoria 2019) It also possesses radiometric resolution at satisfactory level which enables the sensors on-board to distinguish different levels of signal intensity. The following is a video summary of the 2019 to 2020 bushfire air pollutant spread in Australia which resulted in low AQI in a great portion of the country’s residential areas not to mention destruction of many homes. (Tiernan and O’Mallon 2020)\n\n\n\n\nUtilizing the Sentinel 5P data(Trinder and Liu 2020), this proposed project aligns with the following UN Sustainable Development Goals:\n\n\n\n\n\n\n\n\nContribution (by Implementing Proposed Research/Development)\nSDG\nDescription\n\n\n\n\nContribute to the prevention of human respiratory damage caused by smogs from burning forest.\nUN SDG 3\nGood Health and Well-being, ensure people lives a healthy environment, promote well-being for all ages.\n\n\nProper monitoring and timely alerts, contributes to the enhancement of the built environment and overall community safety.\nUN SDG 11\nSustainable, resilient, inclusive and safe cities/communities.\n\n\nActively monitoring wild fires and smogs produced can offer insights and guidance for mitigation.\nUN SDG 13\nTake urgent actions against climate change.\n\n\nThis proposal can contribute to the sustainable of land resources and terrestrial ecosystems.\nUN SDG 15\nSustainable management of land, forests and biodiversity.\n\n\n\nNASA’s Fire Information for Resource Management System (FIRMS) can also be integrated into the workflow. Using remote sensing for monitoring wild fire monitoring has long been proposed for Eastern Australia. (Milne 1986)\nBy extracting values from the daily Sentinel 5p data, we can monitor the wildfire and combine the ground weather/air quality monitoring data, to determine how the polluted air will impact the densely populated area (mapping the air monitoring data over the building footprint in Australia) thus, provide intervention implications for distributing devices and masks. In the literature, similar was workflow proposed for monitoring wild fires in the US. (Kochanski et al. 2021)\n\n\n\nSentinel 5P, Feb 01 to Feb 06, 2020, NO2 level Around Melbourne\n\n\nAs in many regions of the world, residential AQI can be dramatically affected by wildfires, therefore, it is crucial to have a integrated pipeline for the monitoring of harmful aerosol spike which is also incorporated into the policy stack and is dedicated with ample resources.\n\n\n\nSentinel 5P image Overlay with Map around (well, again, “around” and covering VIC and NSW) Melbourne (Time window set to December 01, 2019 to February 06, 2020)\n\n\n\n\nCurrent Policy Stack and Wofkflow\nAs a vibrant metropolis in the state of Victoria, the local councils and state government around the Greater Melbourne Area, has implemented air quality policies aimed at safeguarding the health and well-being of their residents.\n\n\n\nProposed Workflow Serving as an Add-on to the Current Government Workflow and Policy Stack\n\n\n\nEnvironment Protection Amendment Act 2018: This act introduces a general environmental duty that requires proactive risk management to prevent harm to public health and the environment, including air quality impacts.\nEPA Victoria’s AirWatch: A platform that offers real-time air quality information to the public, including an AQI that categorizes air quality levels and provides health advisories, enabling residents to make informed decisions about outdoor activities.\n\n\n\nProposed Mitigation\nIn light of this,this proposal aims to integrate state-of-art remote sensing technology into Melbourne’s current air quality management workflow, offering a multifaceted approach to mitigate air pollution risks:\n\nEstablishment of High-Frequency Sentinel Points: By setting up strategically positioned sentinel points equipped with remote sensing capabilities, we propose to advance the forecasting of Points of Interest (POIs) for early air quality alerts. This system will enable the detection of potential air quality deterioration before polluted air approaches the residential vicinity, allowing for proactive measures to be taken.\nDeployment of Air Filtration and Respiratory Device Stations: Recognizing the immediate health impacts of poor air quality, we plan to establish stations across key urban and suburban locations for the distribution of air filtering and respiratory devices. These stations will ensure that citizens have timely access to necessary protective equipment against smoke and pollutants. Ideally, the station can be established inside local hospitals or clinics.\nEnhanced Emergency Evacuation Planning: Agent-Based Modeling (ABM) methods alongside satellite imagery analysis will be employed to refine emergency evacuation planning. By identifying optimal evacuation routes and safe zones in advance, the updated workflow will facilitate efficient relocation strategies during smoky conditions, ensuring public safety and minimizing chaos.\n\n\n\nImplementation and Emergency Planning Techniques\nOur methodology leverages state-of-the-art remote sensing technology, including the analysis of satellite data from platforms such as Sentinel-5P, to offer unparalleled insights into air quality dynamics. The integration of ABM methods will further enhance our predictive capabilities, allowing for the simulation of various scenarios and the formulation of robust emergency response strategies.\n\n\nConclusion\nBy integrating advanced remote sensing technology into the city’s existing workflow, we aim not only to protect the well-being of Melbourne’s citizens but also to set a new standard for urban air quality management worldwide."
  },
  {
    "objectID": "week4.html#literature-review-and-applications",
    "href": "week4.html#literature-review-and-applications",
    "title": "Week 4 Remote Sensing and Policy Implications",
    "section": "Literature Review and Applications",
    "text": "Literature Review and Applications\nThe exploration of policy and global agenda, combined with the review of current literature, made this week’s class and practical a proper warm-up for the group assessment. I have also combed through the literature and policy base briefly, to further analyze the interplay between remote sensing, policy and air quality.\nEarly in the 2000s, studies have proposed the potentials of incorporating remote sesing into the air quality policy frameworks. (Veefkind et al. 2007) Aside from the potential of forecasting emergency air pollution caused by wildfires or other incidents, recent literature has also indicated the transformative potential of remote sensing in air quality monitoring.(Sokhi et al. 2022) Other researchers has highlighted the application of remote sensing for timely data on aerosol pollutants. (Gupta et al. 2006) therefore, the integration of remote sensing air quality monitoring, could also contribute to the approximate verification and robust back-up for ground air quality data collection. (Bechle, Millet, and Marshall 2013) To generalize the impact of urban air quality monitoring with remote sensing, researchers also suggested that remote sensing can be incorporated in the long-term exposure assessment of air pollutants (Van Donkelaar et al. 2015) and be utilized to discover hidden air pollution patterns. (Verma et al. 2023) Although the current policy frameworks around the world are including satellite images into air quality monitoring, the spatial and temporal resolution of such observation data could be further improved, offering policy makers and environmental agencies more detailed and timely knowledge on the air quality. Potential research directions could explore finer pollution detection,(Huang et al. 2022) establishing near real-time or real time data acquisitions,(Geng et al. 2021) compatibility or fusion with other key environmental metrics monitoring systems. (Prados et al. 2010) and a more hybrid approached in terms of acquiring air quality data such as combining the satellite observations with UAV images. (Budde et al. 2017)"
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "Week 4 Remote Sensing and Policy Implications",
    "section": "Reflection",
    "text": "Reflection\nThe implications of such research are profound for policy-making, it can even contribute to a more data-driven paradigm shift as the data-driven planning. By leveraging remote sensing data, policymakers can benefit from timely and accurate information on the hazardous smoke plumes, their potential movement patterns and impact on overall urban air quality. From the test use of Sentinel 5P data shown above, we can conclude that the resolution overall is inadequate for predicting the movement of the pollutant clusters in the air. In addition, the remote sensing detection and forecasting, ought to be a value-addition or redundant measure to existing air quality measurement and monitoring frameworks and policy instruments. It is also obvious that integrating remote sensing data with real-time sensor data or other air quality monitoring data can pose technique challenges.\nIn summary, the exploration of air quality monitoring, policy interventions, and remote sensing, opens up a new realm of environmental protection and policy implementation. It exemplifies the innovation synergy between technology and policy by introducing remote sensing data analysis to both local and global environmental strategies."
  },
  {
    "objectID": "week4.html#concept-illustration-video",
    "href": "week4.html#concept-illustration-video",
    "title": "Week 4 Remote Sensing and Policy Implications",
    "section": "Concept Illustration Video",
    "text": "Concept Illustration Video\nAs a rather off-track side-quest, I also generated this with text-prompt on Stable Video:\n\n\n\n\nIt is not a geographically accurate depiction as the forest distribution is clearly off, but as a measure for quickly formatting initial illustrations the current development is beyond my expectation.\n\n\n\n\nBechle, Matthew J, Dylan B Millet, and Julian D Marshall. 2013. “Remote Sensing of Exposure to NO2: Satellite Versus Ground-Based Measurement in a Large Urban Area.” Atmospheric Environment 69: 345–53.\n\n\nBhatta, Basudeb, S Saraswati, and D Bandyopadhyay. 2010. “Urban Sprawl Measurement from Remote Sensing Data.” Applied Geography 30 (4): 731–40.\n\n\nBudde, Matthias, Till Riedel, Michael Beigl, Klaus Schäfer, Stefan Emeis, Josef Cyrys, Jürgen Schnelle-Kreis, et al. 2017. “SmartAQnet: Remote and in-Situ Sensing of Urban Air Quality.” In Remote Sensing of Clouds and the Atmosphere XXII, 10424:19–26. SPIE.\n\n\nGeng, Guannan, Qingyang Xiao, Shigan Liu, Xiaodong Liu, Jing Cheng, Yixuan Zheng, Tao Xue, et al. 2021. “Tracking Air Pollution in China: Near Real-Time PM2. 5 Retrievals from Multisource Data Fusion.” Environmental Science & Technology 55 (17): 12106–15.\n\n\nGhaffarian, Saman, Norman Kerle, and Tatiana Filatova. 2018. “Remote Sensing-Based Proxies for Urban Disaster Risk Management and Resilience: A Review.” Remote Sensing 10 (11): 1760.\n\n\nGupta, Pawan, Sundar A Christopher, Jun Wang, Robert Gehrig, YC Lee, and Naresh Kumar. 2006. “Satellite Remote Sensing of Particulate Matter and Air Quality Assessment over Global Cities.” Atmospheric Environment 40 (30): 5880–92.\n\n\nHansen, Matthew C, Peter V Potapov, Rebecca Moore, Matt Hancher, Svetlana A Turubanova, Alexandra Tyukavina, David Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53.\n\n\nHuang, Yuhan, Casey KC Lee, Yat-Shing Yam, Wai-Chuen Mok, John L Zhou, Yuan Zhuang, Nic C Surawski, Bruce Organ, and Edward FC Chan. 2022. “Rapid Detection of High-Emitting Vehicles by on-Road Remote Sensing Technology Improves Urban Air Quality.” Science Advances 8 (5): eabl7575.\n\n\nKochanski, Adam K, Farren Herron-Thorpe, Derek V Mallia, Jan Mandel, and Joseph K Vaughan. 2021. “Integration of a Coupled Fire-Atmosphere Model into a Regional Air Quality Forecasting System for Wildfire Events.” Frontiers in Forests and Global Change 4: 728726.\n\n\nLi, Linyi, Tingbao Xu, and Yun Chen. 2016. “Improved Urban Flooding Mapping from Remote Sensing Images Using Generalized Regression Neural Network-Based Super-Resolution Algorithm.” Remote Sensing 8 (8): 625.\n\n\nMacLachlan, Andrew, Eloise Biggs, Gareth Roberts, and Bryan Boruff. 2017. “Urban Growth Dynamics in Perth, Western Australia: Using Applied Remote Sensing for Sustainable Future Planning.” Land 6 (1): 9.\n\n\nMilne, Anthony Kinnaird. 1986. “The Use of Remote Sensing in Mapping and Monitoring Vegetational Change Associated with Bushfire Events in Eastern Australia.” Geocarto International 1 (1): 25–32.\n\n\nPrados, Ana I, Gregory Leptoukh, Chris Lynnes, James Johnson, Hualan Rui, Aijun Chen, and Rudolf B Husar. 2010. “Access, Visualization, and Interoperability of Air Quality Remote Sensing Data Sets via the Giovanni Online Tool.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 3 (3): 359–70.\n\n\nSokhi, Ranjeet S, Nicolas Moussiopoulos, Alexander Baklanov, John Bartzis, Isabelle Coll, Sandro Finardi, Rainer Friedrich, et al. 2022. “Advances in Air Quality Research–Current and Emerging Challenges.” Atmospheric Chemistry and Physics 22 (7): 4615–4703.\n\n\nStefanov, William L, and Anthony J Brazel. 2007. “Challenges in Characterizing and Mitigating Urban Heat Islands—a Role for Integrated Approaches Including Remote Sensing.” In Applied Remote Sensing for Urban Planning, Governance and Sustainability, 117–35. Springer.\n\n\nTiernan, Finbar, and Eamonn O’Mallon. 2020. “Australia’s 2019–20 Bushfire Season.” The Canberra Times, January. https://www.canberratimes.com.au/story/6600958/australias-2019-20-bushfire-season/.\n\n\nTrinder, John, and Qingxiang Liu. 2020. “Assessing Environmental Impacts of Urban Growth Using Remote Sensing.” Geo-Spatial Information Science 23 (1): 20–39. https://doi.org/10.1080/10095020.2019.1710438.\n\n\nVan Donkelaar, Aaron, Randall V Martin, Michael Brauer, and Brian L Boys. 2015. “Use of Satellite Observations for Long-Term Exposure Assessment of Global Concentrations of Fine Particulate Matter.” Environmental Health Perspectives 123 (2): 135–43.\n\n\nVan Westen, CJ. 2000. “Remote Sensing for Natural Disaster Management.” International Archives of Photogrammetry and Remote Sensing 33 (B7/4; PART 7): 1609–17.\n\n\nVeefkind, P, RF Van Oss, H Eskes, Annette Borowiak, F Dentner, and Julian Wilson. 2007. “The Applicability of Remote Sensing in the Field of Air Pollution.” Institute for Environment and Sustainability, Italy 59: 1–54.\n\n\nVerma, Sunita, Tanu Gangwar, Janhavi Singh, Divya Prakash, and Swagata Payra. 2023. “Urban Air Quality Monitoring and Modelling Using Ground Monitoring, Remote Sensing, and GIS.” In Geospatial Analytics for Environmental Pollution Modeling: Analysis, Control and Management, 213–47. Springer.\n\n\nVictoria, Environmental Protection Authority. 2019. “EPA AirWatc.” https://www.epa.vic.gov.au/for-community/airwatch."
  },
  {
    "objectID": "week5.html#group-assessment-key-points",
    "href": "week5.html#group-assessment-key-points",
    "title": "Week 5 More on Temperature and Group Work Discussion",
    "section": "Group Assessment Key Points",
    "text": "Group Assessment Key Points\nHere are some key takeaways for group assessment references:\n\nHow to perform the feasibility analysis? Approach from the following aspects:\n\nTechnical: Can we do it with the tech we have?\nEconomic: Is it worth the hassle?\nLegal: Are we breaking any local or international laws?\nOperational: How will the project unravel?\nScheduling: When to do what?\n\nCommon global agendas related to remote sensing and urban studies:\n\nUN Sustainable Development Goals\nthe Sendai Framework for Disaster Risk Reduction 2015-2030\nThe New Urban Agenda (NUA)\nThe Global Green New Deal (GND)\n\nOther key points are that we agreed upon for this project is to develop the work covered in the pitch into Work-packs, perform SWOT analysis, design automated Data Pipelines, and adding a Gantt Chart.\nThe topic and scope is also settle with the help of Andy and our PGTAS! (But the brainstorming is utterly a thrill since everyone has contributed novel ideas to develop!)"
  },
  {
    "objectID": "week7.html#classification-methods-in-remote-sensing",
    "href": "week7.html#classification-methods-in-remote-sensing",
    "title": "Week 7 Classification with Google Earth Engine I",
    "section": "Classification Methods in Remote Sensing",
    "text": "Classification Methods in Remote Sensing\nIn the context of remote sensing, there are several classification methods, ranging from logistic regression to\n\nCART\nCART was originally proposed by Breiman et al. Breiman et al. (1984)\n\n\nRandom Forest\nConsumer’s/User’s accuracy refers to the probability that a pixel classified into a given category actually represents that category on the ground. It is calculated for each class by dividing the number of correctly classified pixels (true positives) for that class by the total number of pixels that were classified into that class (both true positives and false positives).\nHere’s a more detailed breakdown:\n\nCorrect (True Positives): The number of instances where the model correctly predicted a specific class.\nTotal (True Positives + False Positives): The sum of instances where the model predicted a specific class (correctly or incorrectly).\n\nThe Resubstitution Error Matrix, also known as a confusion matrix or error matrix, is a specific type of confusion matrix generated by evaluating the classification algorithm on the same dataset that was used to train the model. In other words, it’s the classification report you get when you test your model on the training data itself.\nHere’s what it typically includes:\n\nTrue Positives (TP): Correctly classified positive cases.\nTrue Negatives (TN): Correctly classified negative cases.\nFalse Positives (FP): Negative cases incorrectly classified as positive (Type I error).\nFalse Negatives (FN): Positive cases incorrectly classified as negative (Type II error).\n\nThe Resubstitution Error Matrix is a tool for understanding the performance of a classification model, and it’s particularly useful for identifying the types of errors a model is making. However, because it uses the same data for both training and testing, it may not provide a realistic estimate of the model’s performance on unseen data due to overfitting.\nIt’s important to use this matrix with caution and to complement it with additional validation techniques, such as cross-validation or a test on a separate validation dataset, to evaluate the model’s ability to generalize to new, unseen data.\n\n\nPractical Results Analysis\nPixel wise, 70/30 split,\nhow is it splitted?\n\n\n\n\nGreater Bristol Clip Median\n\n\n\n\n\nComparison of Satellite Layer from GEE and Classification Result\n\n\n\n\n\nFirst Classification\n\n\n\n\n\nPixel-wise Classification\n\n\n\nOverall results in GEE App:\n\n&lt;/p&gt;\n\n\n\n\nModels Used in Practical\nThe pixel-wise approach divided the image pixel points randomly into training (70%) and validation (30%) sets. The training set was then fed to train a random forest to classify the image, and the the RF classifier classified the Bristol clip image to create a classified map.\n\n\nInterpreting the Model Metrics\nConfusion matrix for training results:\n\\[\nConfusion Matrix = \\begin{bmatrix}\n\\ 709&0&2&0&0&1 \\\\\n\\ 0&0&0&0&0&0 \\\\\n\\ 9&0&712&0&0&1 \\\\\n\\ 0&0&0&738&0&0 \\\\\n\\ 0&0&0&0&704&0 \\\\\n\\ 0&0&0&0&0&678 \\\\\n\\end{bmatrix}\n\\]\nThe overall training accuracy is calculated at:\n\\[\nTraining \\ Accucracy = \\frac{3541}{3554} = 99.63\\%\n\\]\nFor testing the confusion matrix is:\n\\[\nConfusion Matrix = \\begin{bmatrix}\n\\ 265&0&14&0&0&9 \\\\\n\\ 0&0&0&0&0&0 \\\\\n\\ 43&0&233&1&0&1 \\\\\n\\ 1&0&0&261&0&1 \\\\\n\\ 0&0&0&0&296&0 \\\\\n\\ 0&0&0&0&0&322 \\\\\n\\end{bmatrix}\n\\]\nTesting Accuracy\n\\[\nValidation \\ Accucracy = \\frac{1377}{1446} = 95.23\\%\n\\]\nThis suggest a high testing accuracy, but it may also indicate over-fitting for we did not calibrate the model carefully and perform solid feature engineering."
  },
  {
    "objectID": "week7.html#outlook-of-ssl-in-remote-sensing",
    "href": "week7.html#outlook-of-ssl-in-remote-sensing",
    "title": "Week 7 Classification with Google Earth Engine I",
    "section": "Outlook of SSL in Remote Sensing",
    "text": "Outlook of SSL in Remote Sensing\nThe current development in the literature of remote sensing image classification, CNN and other supervised learning approaches, although have gained much attention in the past 10 years, may be limited. Large amount of labelled cat images is hard to acquire, not to mention the satellite images covering years of daily images over vast lands, thus small amount of labelled data paradigm will be promising. (Alosaimi et al. 2023) The challenge, however, still lies in the fact that massive amount of data cannot be sole relied on unsupervised clustering methods, on top of that, iterative clustering methods lacks explanability too. Therefore, researcher checking out the usage of SSL do find out that\nhttps://pubmed.ncbi.nlm.nih.gov/36624136/#full-view-affiliation-1"
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "Week 7 Classification with Google Earth Engine I",
    "section": "Reflection",
    "text": "Reflection\nFor this week’s practical, I picked the water polygon from the sea near Bristol, on further remark, I realised that the model probably did not capture Bristol’s rivers, due to the fact that I have selected sea water as sample class for water. Such a result may also stem from the fact that the Bristol river in the image was not significant, thus, such algorithms for now could improve performance for a finer resolution satellite image collection.\nOn further notice, I do find tree-based methods deeply rooted from traditional statistics and computer science. I could recall a concept named B-Tree that I learnt in the big data courses back then. With Upon reviewing the history of machine learning, I do realised how powerful inter-disciplinary research and studies can boost the development of an area of study. It felt like as if statistics is the Midas golden touch for ML to boom. It was only the combination of many subjects and paradigms that give birth to the modern statistical learning.\n\n\n\n\nAlosaimi, Najd, Haikel Alhichri, Yakoub Bazi, Belgacem Ben Youssef, and Naif Alajlan. 2023. “Self-Supervised Learning for Remote Sensing Scene Classification Under the Few Shot Scenario.” Scientific Reports 13 (1): 433.\n\n\nBreiman, L., J. Friedman, C. J. Stone, and R. A. Olshen. 1984. Classification and Regression Trees. Taylor & Francis. https://books.google.co.uk/books?id=JwQx-WOmSyQC."
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "Week 8 Classification with Google Earth Engine II",
    "section": "",
    "text": "asdasd\n1.     Add more Critiques to the literature you reviewed, extend the current research.\n2.     Structure the contents better, give a clear architecture on the right sides of the webpage."
  },
  {
    "objectID": "week9.html#introduction-to-sar",
    "href": "week9.html#introduction-to-sar",
    "title": "Week 9 Synthetic Aperture Radar",
    "section": "Introduction to SAR",
    "text": "Introduction to SAR\nSAR is a powerful remote sensing method for gathering high-resolution images of the Earth’s surface.\nThis charac\ncan collect data using different polarization.\n\nSAR Overview\n\nA1\n\n\nAperture\nLonger Apertures = Finer Resolution\n\n\n\nOptical vs. Radar Remote Sensing\nPros and Cons\nPenetrating cloud cover\ngetting the SAR collections in GEE:\n\n\nRecent Research\nembed js code:\n\n\nPractical: London Outdoor Gym Identification"
  },
  {
    "objectID": "week10.html",
    "href": "week10.html",
    "title": "Week 10 Group Presentations",
    "section": "",
    "text": "This week we had two intense sessions packed with interesting remote sensing pitch-style presentations. The following is a Google Earth Engine App that I have made for viewing parts of the intended raw data for our pitch. The app may take a while to load as the Google Open Buildings dataset is large.\n\n\n\n\nOur team’s name is developed from Roman Goddess of Flowers and Olympian Goddess of the harvest and agriculture. The slides are here.\nWe are honored to be invited to ask question for TeamXYZ and their pitch on an Air Pollution management solution-suite designed for Mumbai. We asked about their future plans and the reply was solid and informative, their overall design and open approach to stakeholder engagement plans are quite impressive.\n\n\n\nMe Presenting Our Methodology Design"
  },
  {
    "objectID": "summary.html#rs-theory-and-ml-learning",
    "href": "summary.html#rs-theory-and-ml-learning",
    "title": "Remote Sensing Term Recap",
    "section": "RS Theory and ML Learning",
    "text": "RS Theory and ML Learning\n\nPCA explained by Hyeon Gu Kim"
  },
  {
    "objectID": "summary.html#additional-gee-materials",
    "href": "summary.html#additional-gee-materials",
    "title": "Remote Sensing Term Recap",
    "section": "Additional GEE Materials",
    "text": "Additional GEE Materials\n\nClipping Polygons in GEE by Youtuber Fech\nGEE data catalog\nGEE community catalog\nGEE Map by Professor. Qiusheng Wu"
  },
  {
    "objectID": "summary.html#html-css-and-quarto",
    "href": "summary.html#html-css-and-quarto",
    "title": "Remote Sensing Term Recap",
    "section": "HTML, CSS and Quarto",
    "text": "HTML, CSS and Quarto\nHere are a list of resources that I have used and adapted for this Quarto book:\n\nEmbedding multiple images\nEmbedding videos"
  },
  {
    "objectID": "summary.html#future-works",
    "href": "summary.html#future-works",
    "title": "Remote Sensing Term Recap",
    "section": "Future Works",
    "text": "Future Works\nThe trend now seems to be building application with Python + GEE, therefore, I am planning to use the Python / GEE tool suite for parts of the visualization work with thesis work. Hopefully it will be interactive and with a touch of satellite images showing the road networks for the transport in a city."
  },
  {
    "objectID": "rs_acronym.html",
    "href": "rs_acronym.html",
    "title": "Acronyms and Key Concepts in Remote Sensing",
    "section": "",
    "text": "AOI: Area of Interest\nARVI: Atmospherically Resistant Vegetation Index\nAVHRR: Advanced Very High Resolution Radiometer\nAzimuth: This is the angle between a reference direction and the line between the observer/sensor and a specific point of interest on the ground.\nCART:\nDEM/DSM/DTM: Digital Elevation Model / Digital Surface Model / Digital Terrain Model. This article and explains well the differences between DEM, DTM and DSM.\nEO: Earth Observation\nEOS: Earth Observing System\nESA: European Space Agency\nEVI: Enhanced Vegetation Index\nGIS: Geographic Information System\nGAUL: Global Administrative Unit Layer:\nGLCM: Gray-Level Co-occurrence Matrix. This lecture note is really helpful in understanding the details of GLCM.\nGNDVI: Green Normalized Difference Vegetation Index\nGOES: Geostationary Operational Environmental Satellite\nGSO: Geosynchronous Orbit, this is an orbit where, from the observer’s (directly on the ground below the point of the object in orbit) reference frame, the object in orbit is stationary. More detailed explanation is found here.\nIFOV: Instantaneous Field of View. Refers to the area on the ground, that a sensor in orbit can see and measure whenever it is ordered to.\nLandSat: Land Satellite, more details on deciding which Landsat collection to import see here.\nLiDAR: Light Detection and Ranging\nLULC: Land Use and Land Cover\nMODIS: Moderate Resolution Imaging Spectroradiometer\nMSAVI: Modified Soil-Adjusted Vegetation Index\nNDMI: Normalized Difference Moisture Index.\nNDVI: Normalized Difference Vegetation Index\nNDWI: Normalized Difference Water Index\nNOAA: National Oceanic and Atmospheric Administration\nPCA: Principal Component Analysis, a statistical technique used to reduce data dimensionality, prioritising significant features by transforming correlated bands into uncorrelated components.\nPOI: Point of Interest\nRF: Random Forest\nROI: Region of Interest\nSAVI: Soil-Adjusted Vegetation Index\nSNAP: Sentinel Application Platform, a software platform used for processing and analyzing satellite data, mostly European Space Agency’s Sentinel series Earth Observation data.\nSVM: Support Vector Machine\nUAV: Unmanned Aerial Vehicle"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alosaimi, Najd, Haikel Alhichri, Yakoub Bazi, Belgacem Ben Youssef, and\nNaif Alajlan. 2023. “Self-Supervised Learning for Remote Sensing\nScene Classification Under the Few Shot Scenario.” Scientific\nReports 13 (1): 433.\n\n\nAmani, Meisam, Arsalan Ghorbanian, Seyed Ali Ahmadi, Mohammad Kakooei,\nArmin Moghimi, S Mohammad Mirmazloumi, Sayyed Hamed Alizadeh Moghaddam,\net al. 2020. “Google Earth Engine Cloud Computing Platform for\nRemote Sensing Big Data Applications: A Comprehensive Review.”\nIEEE Journal of Selected Topics in Applied Earth Observations and\nRemote Sensing 13: 5326–50.\n\n\nBatty, Michael. 2013. “Big Data, Smart Cities and City\nPlanning.” Dialogues in Human Geography 3 (3): 274–79.\n\n\nBechle, Matthew J, Dylan B Millet, and Julian D Marshall. 2013.\n“Remote Sensing of Exposure to NO2: Satellite Versus Ground-Based\nMeasurement in a Large Urban Area.” Atmospheric\nEnvironment 69: 345–53.\n\n\nBreiman, L., J. Friedman, C. J. Stone, and R. A. Olshen. 1984.\nClassification and Regression Trees. Taylor & Francis. https://books.google.co.uk/books?id=JwQx-WOmSyQC.\n\n\nBudde, Matthias, Till Riedel, Michael Beigl, Klaus Schäfer, Stefan\nEmeis, Josef Cyrys, Jürgen Schnelle-Kreis, et al. 2017.\n“SmartAQnet: Remote and in-Situ Sensing of Urban Air\nQuality.” In Remote Sensing of Clouds and the Atmosphere\nXXII, 10424:19–26. SPIE.\n\n\nCardille, Jeffrey A, Nicholas E Clinton, Morgan A Crowley, and David S\nSaah. 2022. “Cloud-Based Remote Sensing with Google Earth Engine:\nProcess and Prospects from a Large Edited Open-Access Book.” In\nAGU Fall Meeting Abstracts, 2022:ED32D–0552.\n\n\nChristaki, Marianna, Christos Vasilakos, Ermioni-Eirini Papadopoulou,\nGeorgios Tataris, Ilias Siarkos, and Nikolaos Soulakellis. 2022.\n“Building Change Detection Based on a Gray-Level Co-Occurrence\nMatrix and Artificial Neural Networks.” Drones 6 (12):\n414.\n\n\nGao, Bo-Cai. 1996. “NDWI—a Normalized Difference Water Index for\nRemote Sensing of Vegetation Liquid Water from Space.” Remote\nSensing of Environment 58 (3): 257–66.\n\n\nGeng, Guannan, Qingyang Xiao, Shigan Liu, Xiaodong Liu, Jing Cheng,\nYixuan Zheng, Tao Xue, et al. 2021. “Tracking Air Pollution in\nChina: Near Real-Time PM2. 5 Retrievals from Multisource Data\nFusion.” Environmental Science & Technology 55 (17):\n12106–15.\n\n\nGitelson, Anatoly A, Yoram J Kaufman, and Mark N Merzlyak. 1996.\n“Use of a Green Channel in Remote Sensing of Global Vegetation\nfrom EOS-MODIS.” Remote Sensing of Environment 58 (3):\n289–98.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth Engine:\nPlanetary-Scale Geospatial Analysis for Everyone.” Remote\nSensing of Environment 202: 18–27.\n\n\nGupta, Pawan, Sundar A Christopher, Jun Wang, Robert Gehrig, YC Lee, and\nNaresh Kumar. 2006. “Satellite Remote Sensing of Particulate\nMatter and Air Quality Assessment over Global Cities.”\nAtmospheric Environment 40 (30): 5880–92.\n\n\nHuang, Yuhan, Casey KC Lee, Yat-Shing Yam, Wai-Chuen Mok, John L Zhou,\nYuan Zhuang, Nic C Surawski, Bruce Organ, and Edward FC Chan. 2022.\n“Rapid Detection of High-Emitting Vehicles by on-Road Remote\nSensing Technology Improves Urban Air Quality.” Science\nAdvances 8 (5): eabl7575.\n\n\nHuete, Alfredo, Kamel Didan, Tomoaki Miura, E Patricia Rodriguez, Xiang\nGao, and Laerte G Ferreira. 2002. “Overview of the Radiometric and\nBiophysical Performance of the MODIS Vegetation Indices.”\nRemote Sensing of Environment 83 (1-2): 195–213.\n\n\nHuete, AR. 1988. “A Soil-Adjusted Vegetation Index (SAVI). Remote\nSsensing of Environment, 25, 295-309.”\n\n\nKaufman, Yoram J, and Didier Tanre. 1992. “Atmospherically\nResistant Vegetation Index (ARVI) for EOS-MODIS.” IEEE\nTransactions on Geoscience and Remote Sensing 30 (2): 261–70.\n\n\nKochanski, Adam K, Farren Herron-Thorpe, Derek V Mallia, Jan Mandel, and\nJoseph K Vaughan. 2021. “Integration of a Coupled Fire-Atmosphere\nModel into a Regional Air Quality Forecasting System for Wildfire\nEvents.” Frontiers in Forests and Global Change 4:\n728726.\n\n\nLan, Zeying, and Yang Liu. 2018. “Study on Multi-Scale Window\nDetermination for GLCM Texture Description in High-Resolution Remote\nSensing Image Geo-Analysis Supported by GIS and Domain\nKnowledge.” ISPRS International Journal of\nGeo-Information 7 (5): 175.\n\n\nMa, Lei, Yu Liu, Xueliang Zhang, Yuanxin Ye, Gaofei Yin, and Brian Alan\nJohnson. 2019. “Deep Learning in Remote Sensing Applications: A\nMeta-Analysis and Review.” ISPRS Journal of Photogrammetry\nand Remote Sensing 152: 166–77.\n\n\nMacLachlan, Andrew, Eloise Biggs, Gareth Roberts, and Bryan Boruff.\n2017. “Urban Growth Dynamics in Perth, Western Australia: Using\nApplied Remote Sensing for Sustainable Future Planning.”\nLand 6 (1): 9.\n\n\nMilne, Anthony Kinnaird. 1986. “The Use of Remote Sensing in\nMapping and Monitoring Vegetational Change Associated with Bushfire\nEvents in Eastern Australia.” Geocarto International 1\n(1): 25–32.\n\n\nMoya, Luis, Homa Zakeri, Fumio Yamazaki, Wen Liu, Erick Mas, and\nShunichi Koshimura. 2019. “3D Gray Level Co-Occurrence Matrix and\nIts Application to Identifying Collapsed Buildings.” ISPRS\nJournal of Photogrammetry and Remote Sensing 149: 14–28.\n\n\nNavalgund, Ranganath R, V Jayaraman, and PS Roy. 2007. “Remote\nSensing Applications: An Overview.” Current Science,\n1747–66.\n\n\nPham-Duc, Binh, Ho Nguyen, Hien Phan, and Quan Tran-Anh. 2023.\n“Trends and Applications of Google Earth Engine in Remote Sensing\nand Earth Science Research: A Bibliometric Analysis Using Scopus\nDatabase.” Earth Science Informatics 16 (3): 2355–71.\n\n\nPrados, Ana I, Gregory Leptoukh, Chris Lynnes, James Johnson, Hualan\nRui, Aijun Chen, and Rudolf B Husar. 2010. “Access, Visualization,\nand Interoperability of Air Quality Remote Sensing Data Sets via the\nGiovanni Online Tool.” IEEE Journal of Selected Topics in\nApplied Earth Observations and Remote Sensing 3 (3): 359–70.\n\n\nQi, Jiaguo, Abdelghani Chehbouni, Alfredo R Huete, Yann H Kerr, and\nSoroosh Sorooshian. 1994. “A Modified Soil Adjusted Vegetation\nIndex.” Remote Sensing of Environment 48 (2): 119–26.\n\n\nReis, Rui S, Nuno Datia, and Matilde Pós-de-Mina Pato. 2020. “A\nPrimer on Understanding Google Earth Engine APIs.” I-ETC:\nISEL Academic Journal of Electronics, Telecommunications and\nComputers 6 (1): 1–11.\n\n\nSabri, S, A Rajabifard, Y Chen, N Chen, and H Sheng. 2022.\n“Editorial: Geospatial Understanding of Sustainable Urban\nAnalytics Using Remote Sensing. Remote Sens. 2022, 14, 2748.” s\nNote: MDPI stays neutral with regard to jurisdictional claims in\npublished ….\n\n\nSokhi, Ranjeet S, Nicolas Moussiopoulos, Alexander Baklanov, John\nBartzis, Isabelle Coll, Sandro Finardi, Rainer Friedrich, et al. 2022.\n“Advances in Air Quality Research–Current and Emerging\nChallenges.” Atmospheric Chemistry and Physics 22 (7):\n4615–4703.\n\n\nSutlieff, Gary, Lucy Berthoud, and Mark Stinchcombe. 2021. “Using\nSatellite Data for CBRN (Chemical, Biological, Radiological, and\nNuclear) Threat Detection, Monitoring, and Modelling.”\nSurveys in Geophysics 42: 727–55.\n\n\nTassi, Andrea, and Marco Vizzari. 2020. “Object-Oriented Lulc\nClassification in Google Earth Engine Combining Snic, Glcm, and Machine\nLearning Algorithms.” Remote Sensing 12 (22): 3776.\n\n\nTiernan, Finbar, and Eamonn O’Mallon. 2020. “Australia’s 2019–20\nBushfire Season.” The Canberra Times, January. https://www.canberratimes.com.au/story/6600958/australias-2019-20-bushfire-season/.\n\n\nTrinder, John, and Qingxiang Liu. 2020. “Assessing Environmental\nImpacts of Urban Growth Using Remote Sensing.” Geo-Spatial\nInformation Science 23 (1): 20–39. https://doi.org/10.1080/10095020.2019.1710438.\n\n\nVan Donkelaar, Aaron, Randall V Martin, Michael Brauer, and Brian L\nBoys. 2015. “Use of Satellite Observations for Long-Term Exposure\nAssessment of Global Concentrations of Fine Particulate Matter.”\nEnvironmental Health Perspectives 123 (2): 135–43.\n\n\nVeefkind, P, RF Van Oss, H Eskes, Annette Borowiak, F Dentner, and\nJulian Wilson. 2007. “The Applicability of Remote Sensing in the\nField of Air Pollution.” Institute for Environment and\nSustainability, Italy 59: 1–54.\n\n\nVerma, Sunita, Tanu Gangwar, Janhavi Singh, Divya Prakash, and Swagata\nPayra. 2023. “Urban Air Quality Monitoring and Modelling Using\nGround Monitoring, Remote Sensing, and GIS.” In Geospatial\nAnalytics for Environmental Pollution Modeling: Analysis, Control and\nManagement, 213–47. Springer.\n\n\nVictoria, Environmental Protection Authority. 2019. “EPA\nAirWatc.” https://www.epa.vic.gov.au/for-community/airwatch.\n\n\nWang, Qingyi, Shenhao Wang, Yunhan Zheng, Hongzhou Lin, Xiaohu Zhang,\nJinhua Zhao, and Joan Walker. 2024. “Deep Hybrid Model with\nSatellite Imagery: How to Combine Demand Modeling and Computer Vision\nfor Travel Behavior Analysis?” Transportation Research Part\nB: Methodological 179: 102869.\n\n\nWilkinson, Graeme G. 1999. “Recent Developments in Remote Sensing\nTechnology and the Importance of Computer Vision Analysis\nTechniques.” Machine Vision and Advanced Image Processing in\nRemote Sensing: Proceedings of Concerted Action MAVIRIC (Machine Vision\nin Remotely Sensed Image Comprehension), 5–11.\n\n\nWilson, Emily Hoffhine, and Steven A Sader. 2002. “Detection of\nForest Harvest Type Using Multiple Dates of Landsat TM Imagery.”\nRemote Sensing of Environment 80 (3): 385–96.\n\n\nXue, Jinru, Baofeng Su, et al. 2017. “Significant Remote Sensing\nVegetation Indices: A Review of Developments and Applications.”\nJournal of Sensors 2017.\n\n\nYan, Peiyao, Feng He, Yajie Yang, and Fei Hu. 2020.\n“Semi-Supervised Representation Learning for Remote Sensing Image\nClassification Based on Generative Adversarial Networks.”\nIEEE Access 8: 54135–44.\n\n\nZhou, Jie, Li Jia, Massimo Menenti, and Xuan Liu. 2021. “Optimal\nEstimate of Global Biome—Specific Parameter Settings to Reconstruct NDVI\nTime Series with the Harmonic ANalysis of Time Series (HANTS)\nMethod.” Remote Sensing 13 (21): 4251.\n\n\nZhu, Zhe. 2017. “Change Detection Using Landsat Time Series: A\nReview of Frequencies, Preprocessing, Algorithms, and\nApplications.” ISPRS Journal of Photogrammetry and Remote\nSensing 130: 370–84."
  },
  {
    "objectID": "week4.html#summary-of-remote-sensing-and-policy-implications",
    "href": "week4.html#summary-of-remote-sensing-and-policy-implications",
    "title": "Week 4 Remote Sensing and Policy Implications",
    "section": "Summary of Remote Sensing and Policy Implications",
    "text": "Summary of Remote Sensing and Policy Implications\nThe lecture first introduced the significance of multi-temporal land cover mapping in understanding and managing environmental changes, where remote sensing is particularly meaningful for researchers and policymakers to identify land use changes, deforestation, and urban sprawl. (Bhatta, Saraswati, and Bandyopadhyay 2010)\nAnother major application of remote sensing in terms of shaping the policies, is environmental monitoring. With remote sensing measures such as Synthetic Aprture Radar (SAR), for example, environmental researchers and policy makers are able to monitor the changes of the forests (Hansen et al. 2013) therefore formulate instruments that directly contributes to containing illegal logging. Another key application for remote sensing is for disaster monitoring and response, with high-quality and timely remote sensing data, policymakers now have the capability to tackle large-scale disastrous events such as droughts and forest fires. (Van Westen 2000)\nWith the insights extracted from remote sensing, cities can now monitor and construct strategies for complicated problems such as urban heat island, (Stefanov and Brazel 2007) inner city floods, (Li, Xu, and Chen 2016) further increasing the urban resilience. (Ghaffarian, Kerle, and Filatova 2018) By incorporating spatial data and remote sensing into the making of policy instruments through aligning with the global sustainability agendas such as the New Urban Agenda and the Sustainable Development Goals (SDGs), stakeholders from all aspects can work together to face challenges raised by rapid urbanisation."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote Sensing Learning Diary",
    "section": "",
    "text": "Overview\nThis is the learning diary for CASA0023 Remotely Sensing Cities and Environments."
  },
  {
    "objectID": "index.html#table-of-content",
    "href": "index.html#table-of-content",
    "title": "CASA0023 Remote Sensing Learning Diary",
    "section": "Table of Content",
    "text": "Table of Content\n\nPersonal Introduction\nPart I. Intro to Remote Sensing\n\nWeek 1 Introduction to Remote Sensing\nWeek 2 Quarto and Xaringan\nWeek 3 Atmosphere Corrections\nWeek 4 Remote Sensing and Policy Implications\nWeek 5 More on Temperature and Group Work Discussion\n\nPart II. Remote Sensing with GEE\n\nWeek 6 Introduction to Google Earth Engine\nWeek 7 Classification with GEE Part 1\nWeek 8 Classification with GEE Part 2\nWeek 9 Synthetic Aperture Radar\n\nWeek 10 Group Presentation Week\nSummary\nRemote Sensing Acronyms\nReference"
  }
]